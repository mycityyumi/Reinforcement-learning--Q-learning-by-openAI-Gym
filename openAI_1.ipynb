{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "openAI_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "colab_type": "code",
        "id": "_t70Twb8xO6F",
        "outputId": "ef2242a5-e537-432b-f2e5-10a1998e3642"
      },
      "cell_type": "code",
      "source": [
        "!python3 -m pip install gym\n",
        "!python3 -m pip install tflearn\n",
        "!python3 -m pip install python-opengl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.10.8)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.18.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (0.19.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.11.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.2)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2018.8.24)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n",
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.6/dist-packages (0.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.11.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (4.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.14.6)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->tflearn) (0.46)\n",
            "Collecting python-opengl\n",
            "\u001b[31m  Could not find a version that satisfies the requirement python-opengl (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for python-opengl\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JeS0JG23xO6Q"
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "import tflearn\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "from statistics import mean, median\n",
        "from collections import Counter\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1zFmhQnWxO6U"
      },
      "cell_type": "code",
      "source": [
        "LR = 1e-3\n",
        "env = gym.make('CartPole-v0')\n",
        "env.max_episode_steps = None\n",
        "env._max_episode_steps = None\n",
        "env.reset()\n",
        "goal_steps = 500 #how many step\n",
        "score_requirement = 50\n",
        "initial_game = 10000 #brute force every answer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jLOf7yR1xO6Z"
      },
      "cell_type": "code",
      "source": [
        "def some_random_games_first():\n",
        "    for episode in range(5):\n",
        "        env.reset()\n",
        "        for t in range(200):\n",
        "            env.render() # if you want faster, don't render\n",
        "            action = env.action_space.sample()\n",
        "            observation, reward, done, info = env.step(action)\n",
        "            #observation have 4 values at same time\n",
        "            #print(observation)\n",
        "            if done:\n",
        "                break\n",
        "#some_random_games_first()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "U5SqTVsmxO6c"
      },
      "cell_type": "code",
      "source": [
        "def initial_population():\n",
        "    training_data = []\n",
        "    scores = []\n",
        "    accepted_scores = []\n",
        "    for _ in range(initial_game):\n",
        "        score =0\n",
        "        game_memory = []\n",
        "        prev_observation = []\n",
        "        for _ in range(goal_steps):\n",
        "            action = random.randrange(0,2)\n",
        "            #action = 0 or 1 [left, right]\n",
        "            observation, reward, done, info = env.step(action)\n",
        "            \n",
        "            # notice that the observation is returned FROM the action\n",
        "            # so we'll store the previous observation here, pairing\n",
        "            # the prev observation to the action we'll take.\n",
        "            if len(prev_observation)>0:\n",
        "                #game_memory save all obersation and action\n",
        "                game_memory.append([prev_observation, action])\n",
        "                #print('prev_observation:',prev_observation,' action:',action)\n",
        "                \n",
        "            prev_observation = observation\n",
        "            score +=reward\n",
        "            if done:\n",
        "                break\n",
        "        if score >= score_requirement:\n",
        "            #accepted_scores just save score above score_requirement\n",
        "            accepted_scores.append(score)\n",
        "            #to change action '1'-->[0,1] or action '0' -->[1,0] for suit with numpy data style\n",
        "            # we change to [0,1] because we also keep 0 or 1, but some game have more action, so we use [0,1]\n",
        "            for data in game_memory:\n",
        "                if data[1]== 1:\n",
        "                    output = [0,1]\n",
        "                elif data[1] == 0:\n",
        "                    output = [1,0]\n",
        "                #saving our traning data\n",
        "                training_data.append([data[0],output])\n",
        "        env.reset()\n",
        "        #save all score values of each espiso, also counting value not enough for the requirement\n",
        "        scores.append(score)\n",
        "    #just in case you wanted to reference later\n",
        "    training_data_save = np.array(training_data)\n",
        "    np.save('./saved.npy', training_data_save)\n",
        "    \n",
        "    #some stats here,to further illustrate the neural network magic\n",
        "    print('Average accepted score:', mean(accepted_scores))\n",
        "    print('Median score for accepted scores:', median(accepted_scores))\n",
        "    #counter is keep track how many value repeat\n",
        "    print(Counter(accepted_scores))\n",
        "    return training_data\n",
        "#initial_population()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "G--inXEZYwmO"
      },
      "cell_type": "code",
      "source": [
        "#training_data = initial_population()\n",
        "#training_data\n",
        "i=0\n",
        "#print(training_data[0][0].reshape(-1,4,1))\n",
        "#type(training_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tAMJN7ojYlv9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dữ liệu training và predict sẽ có dạng:\n",
        "- [[[-0.04253177],[-0.21715409],[ 0.03958076],[ 0.28797414]]]\n",
        "- training_data[0][0].reshape(-1,len(training_data[0][0]),1)\n"
      ]
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "TKirT8P4xO6f"
      },
      "cell_type": "code",
      "source": [
        "def neural_network_model(input_size):\n",
        "    #1 in input_size mean just observation source for input \n",
        "    network = input_data(shape=[None, input_size, 1], name='input')\n",
        "    #128 nodes for fisrt layer, each node have activation is relu for linear function\n",
        "    network = fully_connected(network, 128, activation='relu')\n",
        "    #0.8 is keep rate\n",
        "    network = dropout(network, 0.8)\n",
        "    #seconde layer\n",
        "    network = fully_connected(network, 256, activation='relu')\n",
        "    network = dropout(network, 0.8)\n",
        "\n",
        "    network = fully_connected(network, 512, activation='relu')\n",
        "    network = dropout(network, 0.8)\n",
        "    \n",
        "    network = fully_connected(network, 256, activation='relu')\n",
        "    network = dropout(network, 0.8)\n",
        "\n",
        "    network = fully_connected(network, 128, activation='relu')\n",
        "    network = dropout(network, 0.8)\n",
        "\n",
        "    network = fully_connected(network, 2, activation='softmax')\n",
        "    network = regression(network, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
        "    model = tflearn.DNN(network, tensorboard_dir='log')\n",
        "    #sometimes have out of memony, so just change number of layer\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "colab_type": "code",
        "id": "gJsaBMcFxO6i",
        "outputId": "be002d3a-5f9e-414a-e6ba-3786d8816026"
      },
      "cell_type": "code",
      "source": [
        "def train_model(training_data, model=False):\n",
        "    #training_data have pype [[4 observation][0,1 or 1,0]]\n",
        "    #[i[0] for i in training_data] mean all element in first place (4 observations)\n",
        "    # X need np.array because training_data has type is list, can't not reshape -->should be convert to numpy.array type\n",
        "    X = np.array([i[0] for i in training_data]).reshape(-1,len(training_data[0][0]),1)#---> X has shape: (totall number,4,1) -->the official shape for training\n",
        "    #[i[0] for i in training_data] mean all elements in the secon place [0,1] or [1,0]\n",
        "    y = [i[1] for i in training_data] #----> [0,1] or [1,0]\n",
        "    #print(X.shape)\n",
        "    #print(y[0])\n",
        "    if not model:\n",
        "        #run neural_network_model\n",
        "        model = neural_network_model(input_size = len(X[0])) #len(X[0])=4\n",
        "    #just run 1 time becasue model.fit can re-run\n",
        "    model.fit({'input': X}, {'targets': y}, n_epoch=3, snapshot_step=500, show_metric=True, run_id='openai_learning')\n",
        "    #n-epoch in simple case don't too high, <=95% accurate\n",
        "    #snapshot_step mean how much step trained will print out the screen\n",
        "    return model\n",
        "training_data = initial_population()\n",
        "model = train_model(training_data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 1040  | total loss: \u001b[1m\u001b[32m0.66025\u001b[0m\u001b[0m | time: 4.894s\n",
            "| Adam | epoch: 003 | loss: 0.66025 - acc: 0.5916 -- iter: 22144/22207\n",
            "Training Step: 1041  | total loss: \u001b[1m\u001b[32m0.66547\u001b[0m\u001b[0m | time: 4.906s\n",
            "| Adam | epoch: 003 | loss: 0.66547 - acc: 0.5872 -- iter: 22207/22207\n",
            "--\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kw-9t3jLyl7O"
      },
      "cell_type": "code",
      "source": [
        "#model.save('hihi.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gq45s9PidNhX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b4aa090-090f-4ae7-9190-0d54927000a7"
      },
      "cell_type": "code",
      "source": [
        "X=np.array([i[0] for i in training_data]).reshape(-1,len(training_data[0][0]),1)\n",
        "len(X[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7V_Mx2966Y71"
      },
      "cell_type": "code",
      "source": [
        "#model.load('hihi.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "colab_type": "code",
        "id": "HSPJtnAExO6n",
        "outputId": "07c71449-e8ad-4075-d668-8778d207d472"
      },
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "choices = []\n",
        "for each_game in range(10):\n",
        "    score = 0\n",
        "    game_memory = []\n",
        "    prev_obs = []\n",
        "    env.reset()\n",
        "    for _ in range(1000):\n",
        "        #env.render()\n",
        "\n",
        "        if len(prev_obs)==0:\n",
        "            action = random.randrange(0,2)\n",
        "        else:\n",
        "            action = np.argmax(model.predict(prev_obs.reshape(-1,len(prev_obs),1))[0])\n",
        "\n",
        "        choices.append(action)\n",
        "                \n",
        "        new_observation, reward, done, info = env.step(action)\n",
        "        prev_obs = new_observation\n",
        "        game_memory.append([new_observation, action])\n",
        "        score+=reward\n",
        "        if done:\n",
        "          break\n",
        "\n",
        "    scores.append(score)\n",
        "\n",
        "print('Average Score:',sum(scores)/len(scores))\n",
        "print('choice 1:{}  choice 0:{}'.format(choices.count(1)/len(choices),choices.count(0)/len(choices)))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Score: 721.7\n",
            "choice 1:0.49688236109186645  choice 0:0.5031176389081335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "nNgZohV18TiV",
        "outputId": "58b8a6d4-e07d-45b7-c49e-f69ac443c62c"
      },
      "cell_type": "code",
      "source": [
        "list(scores)\n",
        "#max(scores)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[549.0, 1000.0, 1000.0, 1000.0, 1000.0, 362.0, 1000.0, 1000.0, 139.0, 167.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "ZWYpvWCK7yyK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "env._max_episode_seconds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E5MDMdy56eaL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "308c90b7-3638-41ca-c250-baaaffb0bbfb"
      },
      "cell_type": "code",
      "source": [
        "t=model.predict([[[-0.04253177],[-0.21715409],[ 0.03958076],[ 0.28797414]]])\n",
        "t"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49776545, 0.5022345 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    }
  ]
}